{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_feat = torch.tensor([[4,1,7,5],[4,4,2,5],[7,7,2,4],[1,0,2,4]], dtype=torch.float32)\n",
    "input_feat = input_feat.unsqueeze(0).unsqueeze(0)\n",
    "print(input_feat)\n",
    "print(input_feat.shape)\n",
    "conv2d = nn.Conv2d(1, 1, (2,2), stride=1, padding='same', bias=False)\n",
    "print(conv2d.weight)\n",
    "print(conv2d.bias)\n",
    "\n",
    "kernels = torch.tensor([[[[1,0], [2,1]]]], dtype=torch.float32)\n",
    "conv2d.weight = nn.Parameter(kernels, requires_grad=False)\n",
    "print(conv2d.weight)\n",
    "output= conv2d(input_feat)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度可分离卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.rand((3, 5, 5)).unsqueeze(0)\n",
    "print(x, x.shape)\n",
    "in_channels_dw = x.shape[1]\n",
    "out_channels_dw = x.shape[1]\n",
    "kernel_size = 3\n",
    "dw = nn.Conv2d(in_channels_dw, out_channels_dw, kernel_size, 1, padding=\"same\", groups=in_channels_dw)\n",
    "in_channels_pw = out_channels_dw\n",
    "out_channels_pw = 4\n",
    "kernel_size_pw = 1\n",
    "pw = nn.Conv2d(in_channels_pw, out_channels_pw, kernel_size_pw, 1)\n",
    "out = dw(x)\n",
    "print(out.shape)\n",
    "out = pw(dw(x))\n",
    "print(out, out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "空洞卷积\n",
    "- 常用于图像分割，不需要缩小特征图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((3, 5, 5)).unsqueeze(0)\n",
    "conv = nn.Conv2d(in_channels_dw, out_channels_dw, kernel_size, 1, dilation=2)\n",
    "out = conv(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(1))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "    def forward(self, input):\n",
    "        return (input * self.weight) + self.bias\n",
    "\n",
    "w = 2\n",
    "b = 3\n",
    "model = LinearModel()\n",
    "x_train = np.random.randint(low=-10, high=10, size=30)\n",
    "y_train = [w*x+b+random.randint(0,2) for x in x_train]\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "for _ in range(1000):\n",
    "    input = torch.from_numpy(x_train)\n",
    "    output = model(input)\n",
    "    loss = nn.MSELoss()(output, y_train)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "for param in model.named_parameters():\n",
    "    print(param)\n",
    "x = np.asarray(range(-10,11))\n",
    "pre_y = model(torch.from_numpy(x)).detach().numpy()\n",
    "plt.plot(x, pre_y)\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "torch.save(model.state_dict(), './linear_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(1))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "    def forward(self, input):\n",
    "        return (input * self.weight) + self.bias\n",
    "\n",
    "model = LinearModel()\n",
    "model.load_state_dict(torch.load('./linear_model.pth'))\n",
    "model.eval()\n",
    "for param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "from PIL import Image\n",
    "im = Image.open('dog.jpeg')\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])])\n",
    "input_tensor = transform(im).unsqueeze(0)\n",
    "print(alexnet(input_tensor).argmax())\n",
    "# https://gist.github.com/maraoz/388eddec39d60c6d52d4\n",
    "print(alexnet)\n",
    "fc_in_features = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = torch.nn.Linear(fc_in_features, 10)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(),\n",
    "        target_transform=None, download=True)\n",
    "tensor_loader = DataLoader(dataset=cifar10_dataset, batch_size=32)\n",
    "data, _ = next(iter(tensor_loader))\n",
    "grid_tensor = torchvision.utils.make_grid(data, nrow=16, padding=2)\n",
    "display(transforms.ToPILImage()(grid_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# 使用gpu训练\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    # arm mac\n",
    "    device = torch.device(\"mps\")\n",
    "print(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])])\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform,\n",
    "        target_transform=None, download=True)\n",
    "print(len(cifar10_dataset))\n",
    "# tensor_loader = DataLoader(dataset=cifar10_dataset, batch_size=32, pin_memory=True, pin_memory_device=\"mps\")\n",
    "tensor_loader = DataLoader(dataset=cifar10_dataset, batch_size=100)\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "alexnet.classifier[6] = torch.nn.Linear(alexnet.classifier[6].in_features, 10)\n",
    "alexnet = alexnet.to(device)\n",
    "optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "alexnet.train()\n",
    "for epoch in range(3):\n",
    "    for i, item in enumerate(tensor_loader):\n",
    "        x, y = item[0].to(device), item[1].to(device)\n",
    "        output = alexnet(x)\n",
    "        loss = loss_f(output, y)\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch {}, Loss {}'.format(epoch+1,loss))\n",
    "        alexnet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实践图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "class MyCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, kernel_size=3)\n",
    "        self.fc = torch.nn.Linear(16*222*222, 10)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x:torch.Tensor = self.conv1(input)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 使用gpu训练\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    # arm mac\n",
    "    device = torch.device(\"mps\")\n",
    "print(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])])\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform,\n",
    "        target_transform=None, download=True)\n",
    "print(len(cifar10_dataset))\n",
    "tensor_loader = DataLoader(dataset=cifar10_dataset, batch_size=100, num_workers=5)\n",
    "net = MyCNN().to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-4, weight_decay=1e-2, momentum=0.8)\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "net.train()\n",
    "for epoch in range(3):\n",
    "    for i, item in enumerate(tensor_loader):\n",
    "        x, y = item[0].to(device), item[1].to(device)\n",
    "        output = net(x)\n",
    "        loss = loss_f(output, y)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch {}, Loss {}'.format(epoch+1,loss))\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(net, \"mycnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "net:torch.nn.Module = torch.load(\"mycnn.pth\")\n",
    "cifar10_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform,\n",
    "        target_transform=None, download=True)\n",
    "print(len(cifar10_test_dataset))\n",
    "test_tensor_loader = DataLoader(dataset=cifar10_test_dataset, batch_size=1000)\n",
    "net.eval()\n",
    "count = 0\n",
    "for i, item in enumerate(test_tensor_loader):\n",
    "    pre:torch.Tensor = net(item[0].to(\"mps\"))\n",
    "    for j, res in enumerate(pre):\n",
    "        res = res.argmax()\n",
    "        if res != item[1][j].item():\n",
    "            count = count + 1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
